---
title: "Gen.jl : A Tutorial"
format: 
  revealjs:
    scrollable: true
engine: julia
---

```{julia}
#| echo: false
#| output: false

using Pkg
Pkg.instantiate()
```

For `Gen`, the model creation process is similar to `Turing` except for a few differences

-   The `@gen` macro is used to define a model instead of the `@model` macro.

-   The `~` symbol is also used for distribution statements but the syntax for the expression $x\sim N(0,1)$ is `{"x"} ~ normal(0,1)`.

-   The arguments of the model only include fixed quantities that does not have a distribution statement.

Let's look at the Bayesian Logistic Regression model from the `Turing` tutorial 
$$
\begin{align}
a_i &\sim N(0,\sigma^2), &i=1,\ldots,4 \\
y_n &\sim \text{Bern}\left(\text{logistic}\left(\sum_{i=1}^4a_ix_{ni}\right)\right) & n=1,\ldots,N
\end{align}
$$

Note that in the code below, $x,\sigma$ and $N$ are in the argument because the $y_n$'s each have their own distribution statement.

```{julia}
using Gen, MCMCChains
using DynamicPPL, Distributions, LogExpFunctions
using LinearAlgebra, SplittableRandoms, StatsPlots

# model definition
@gen function bayes_logistic_gen(x, N, σ)
    a = [({"a-$i"} ~ normal(0.0, σ)) for i in 1:4]
    for n in 1:N
        v_i = logistic(dot(a,x[n,:]))
        {"y-$n"} ~ bernoulli(v_i)
    end
end

# simulate dataset
rng = SplittableRandom(123)
N = 30
a = [10, 3.5, -0.7, -4.1]
x = randn(rng, 30, 4)
y = [rand(rng,Bernoulli(logistic(dot(a,x[n,:])))) for n in 1:N]
```

Next, let's use a simple coordinate-wise random walk Metropolis-Hastings sampler to sample from our model. There are two important procedures in the function below

-   In the first few lines, we create a `ChoiceMap` object that essentially stores

    -   the graphical model of our model

    -   the values of observation nodes in said graphical model

-   In the rest of the function, we

    -   initialize the model using the syntax `generate(model,(model_arguments),observations)`

    -   choose the subset of random variables to sample from using `select`

    -   loop over the `mh` kernel to sample

```{julia}
function mh_sampler(model, iteration, x, N, σ)
    
    # create a choice map for observations
    observations = Gen.choicemap()
    for n in 1:N
        observations["y-$n"] = y[n]
    end

    # initialize trace and selection
    tr, = generate(model, (x,N,σ), observations)
    
    # store param samples in a vector
    param = [tr["a-$i"] for i in 1:4]
    param_vec = [param]

    # begin sampling
    for t in 1:iteration
        # setup param vector
        param = []

        # mh step
        for i in 1:4
            tr, = mh(tr,select("a-$i"))
            # store new coordinate sample
            push!(param,tr["a-$i"])
        end

        # add new param samples to param vector
        push!(param_vec,param)
    end

    return param_vec
end;
```

Now we can sample from our model

```{julia}
samples = mh_sampler(bayes_logistic_gen, 10000, x, N, 1.0)
```

and, with a helper function to turn the output to a `Chains` object, visualize the result.

```{julia}
function bundle_samples(
    samples, stats=nothing;
    param_names=missing,
    kwargs...,
)
    # state dimension
    d = length(samples[1])
    n = length(samples)

    # Turn all the transitions into a vector-of-vectors.
    if isnothing(stats)
        vals = copy(reduce(hcat, [samples[i] for i in 1:n])')
    else
        vals = copy(reduce(hcat, [vcat(samples[i], vcat(values(stats[i])...)) for i in 1:n])')
    end

    # Check if we received any parameter names.
    if ismissing(param_names)
        param_names = [Symbol("Parameter $i") for i in 1:d]
    end

    if isnothing(stats)
        # Bundle everything up and return a Chains struct.
        return Chains(vals, param_names)
    else
        # Add internal parameter names.
        internal_params = vcat(keys(stats[1])...)
        push!(param_names, internal_params...)

        # Bundle everything up and return a Chains struct.
        return Chains(vals, param_names, (internals=internal_params,))
    end    
end

chain = bundle_samples(samples; param_names = ["a$i" for i in 1:4])
plot(chain)
```